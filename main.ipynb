{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWID Intrusion Detection\n",
    "\n",
    "The AWID dataset is ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \tStep 1: Cleaning and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harman\\AppData\\Local\\Temp\\ipykernel_23316\\2893595333.py:42: DtypeWarning: Columns (37,38,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,74,88) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"./data/original/full_dataset.zip\", compression='zip', header=None, names=header_columns, nrows=200000)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "header_columns = [\n",
    "\t\"frame.interface_id\", \"frame.dlt\", \"frame.offset_shift\", \"frame.time_epoch\",\n",
    "\t\"frame.time_delta\", \"frame.time_delta_displayed\", \"frame.time_relative\",\n",
    "\t\"frame.len\", \"frame.cap_len\", \"frame.marked\", \"frame.ignored\", \"radiotap.version\",\n",
    "\t\"radiotap.pad\", \"radiotap.length\", \"radiotap.present.tsft\", \"radiotap.present.flags\",\n",
    "\t\"radiotap.present.rate\", \"radiotap.present.channel\", \"radiotap.present.fhss\",\n",
    "\t\"radiotap.present.dbm_antsignal\", \"radiotap.present.dbm_antnoise\", \"radiotap.present.lock_quality\",\n",
    "\t\"radiotap.present.tx_attenuation\", \"radiotap.present.db_tx_attenuation\", \"radiotap.present.dbm_tx_power\",\n",
    "\t\"radiotap.present.antenna\", \"radiotap.present.db_antsignal\", \"radiotap.present.db_antnoise\", \n",
    "\t\"radiotap.present.rxflags\", \"radiotap.present.xchannel\", \"radiotap.present.mcs\", \"radiotap.present.ampdu\", \n",
    "\t\"radiotap.present.vht\", \"radiotap.present.reserved\", \"radiotap.present.rtap_ns\", \"radiotap.present.vendor_ns\", \n",
    "\t\"radiotap.present.ext\", \"radiotap.mactime\", \"radiotap.flags.cfp\", \"radiotap.flags.preamble\", \n",
    "\t\"radiotap.flags.wep\", \"radiotap.flags.frag\", \"radiotap.flags.fcs\", \"radiotap.flags.datapad\", \n",
    "\t\"radiotap.flags.badfcs\", \"radiotap.flags.shortgi\", \"radiotap.datarate\", \"radiotap.channel.freq\", \n",
    "\t\"radiotap.channel.type.turbo\", \"radiotap.channel.type.cck\", \"radiotap.channel.type.ofdm\", \"radiotap.channel.type.2ghz\",\n",
    "\t\"radiotap.channel.type.5ghz\", \"radiotap.channel.type.passive\", \"radiotap.channel.type.dynamic\", \"radiotap.channel.type.gfsk\",\n",
    "\t\"radiotap.channel.type.gsm\", \"radiotap.channel.type.sturbo\", \"radiotap.channel.type.half\", \"radiotap.channel.type.quarter\",\n",
    "\t\"radiotap.dbm_antsignal\", \"radiotap.antenna\", \"radiotap.rxflags.badplcp\", \"wlan.fc.type_subtype\", \"wlan.fc.version\",\n",
    "\t\"wlan.fc.type\", \"wlan.fc.subtype\", \"wlan.fc.ds\", \"wlan.fc.frag\", \"wlan.fc.retry\", \"wlan.fc.pwrmgt\", \"wlan.fc.moredata\",\n",
    "\t\"wlan.fc.protected\", \"wlan.fc.order\", \"wlan.duration\", \"wlan.ra\", \"wlan.da\", \"wlan.ta\", \"wlan.sa\", \"wlan.bssid\", \"wlan.frag\",\n",
    "\t\"wlan.seq\", \"wlan.bar.type\", \"wlan.ba.control.ackpolicy\", \"wlan.ba.control.multitid\", \"wlan.ba.control.cbitmap\",\n",
    "\t\"wlan.bar.compressed.tidinfo\", \"wlan.ba.bm\", \"wlan.fcs_good\", \"wlan_mgt.fixed.capabilities.ess\",\n",
    "\t\"wlan_mgt.fixed.capabilities.ibss\", \"wlan_mgt.fixed.capabilities.cfpoll.ap\", \"wlan_mgt.fixed.capabilities.privacy\",\n",
    "\t\"wlan_mgt.fixed.capabilities.preamble\", \"wlan_mgt.fixed.capabilities.pbcc\", \"wlan_mgt.fixed.capabilities.agility\",\n",
    "\t\"wlan_mgt.fixed.capabilities.spec_man\", \"wlan_mgt.fixed.capabilities.short_slot_time\", \"wlan_mgt.fixed.capabilities.apsd\",\n",
    "\t\"wlan_mgt.fixed.capabilities.radio_measurement\", \"wlan_mgt.fixed.capabilities.dsss_ofdm\", \"wlan_mgt.fixed.capabilities.del_blk_ack\",\n",
    "\t\"wlan_mgt.fixed.capabilities.imm_blk_ack\", \"wlan_mgt.fixed.listen_ival\", \"wlan_mgt.fixed.current_ap\", \"wlan_mgt.fixed.status_code\",\n",
    "\t\"wlan_mgt.fixed.timestamp\", \"wlan_mgt.fixed.beacon\", \"wlan_mgt.fixed.aid\", \"wlan_mgt.fixed.reason_code\", \"wlan_mgt.fixed.auth.alg\",\n",
    "\t\"wlan_mgt.fixed.auth_seq\", \"wlan_mgt.fixed.category_code\", \"wlan_mgt.fixed.htact\", \"wlan_mgt.fixed.chanwidth\",\n",
    "\t\"wlan_mgt.fixed.fragment\", \"wlan_mgt.fixed.sequence\", \"wlan_mgt.tagged.all\", \"wlan_mgt.ssid\", \"wlan_mgt.ds.current_channel\",\n",
    "\t\"wlan_mgt.tim.dtim_count\", \"wlan_mgt.tim.dtim_period\", \"wlan_mgt.tim.bmapctl.multicast\", \"wlan_mgt.tim.bmapctl.offset\",\n",
    "\t\"wlan_mgt.country_info.environment\", \"wlan_mgt.rsn.version\", \"wlan_mgt.rsn.gcs.type\", \"wlan_mgt.rsn.pcs.count\", \"wlan_mgt.rsn.akms.count\",\n",
    "\t\"wlan_mgt.rsn.akms.type\", \"wlan_mgt.rsn.capabilities.preauth\", \"wlan_mgt.rsn.capabilities.no_pairwise\", \"wlan_mgt.rsn.capabilities.ptksa_replay_counter\",\n",
    "\t\"wlan_mgt.rsn.capabilities.gtksa_replay_counter\", \"wlan_mgt.rsn.capabilities.mfpr\", \"wlan_mgt.rsn.capabilities.mfpc\", \"wlan_mgt.rsn.capabilities.peerkey\",\n",
    "\t\"wlan_mgt.tcprep.trsmt_pow\", \"wlan_mgt.tcprep.link_mrg\", \"wlan.wep.iv\", \"wlan.wep.key\", \"wlan.wep.icv\", \"wlan.tkip.extiv\", \"wlan.ccmp.extiv\",\n",
    "\t\"wlan.qos.tid\", \"wlan.qos.priority\", \"wlan.qos.eosp\", \"wlan.qos.ack\", \"wlan.qos.amsdupresent\", \"wlan.qos.buf_state_indicated\", # Remove this duplicate\n",
    "\t\"wlan.qos.bit4\", \"wlan.qos.txop_dur_req\", \"data.len\", \"class\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(\"./data/original/full_dataset.zip\", compression='zip', header=None, names=header_columns, nrows=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sum()\n",
    "\n",
    "# No missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains a lot of ?'s. We're just going to drop all columns whose rows contain more than 10%  of ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '?' with NaN\n",
    "df.replace('?', pd.NA, inplace=True)\n",
    "\n",
    "# Calculate the threshold for 10% of the rows\n",
    "threshold = len(df) * 0.1\n",
    "\n",
    "# Drop columns with more than 10% NaN values\n",
    "df.dropna(thresh=threshold, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame.dlt</th>\n",
       "      <th>frame.offset_shift</th>\n",
       "      <th>frame.time_epoch</th>\n",
       "      <th>frame.time_delta</th>\n",
       "      <th>frame.time_delta_displayed</th>\n",
       "      <th>frame.time_relative</th>\n",
       "      <th>frame.len</th>\n",
       "      <th>frame.cap_len</th>\n",
       "      <th>frame.marked</th>\n",
       "      <th>frame.ignored</th>\n",
       "      <th>...</th>\n",
       "      <th>wlan.ccmp.extiv</th>\n",
       "      <th>wlan.qos.tid</th>\n",
       "      <th>wlan.qos.priority</th>\n",
       "      <th>wlan.qos.eosp</th>\n",
       "      <th>wlan.qos.ack</th>\n",
       "      <th>wlan.qos.buf_state_indicated</th>\n",
       "      <th>wlan.qos.bit4</th>\n",
       "      <th>wlan.qos.txop_dur_req</th>\n",
       "      <th>data.len</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.393661e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.393661e+09</td>\n",
       "      <td>0.024271</td>\n",
       "      <td>0.024271</td>\n",
       "      <td>0.024271</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.393661e+09</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.025902</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.393661e+09</td>\n",
       "      <td>0.055325</td>\n",
       "      <td>0.055325</td>\n",
       "      <td>0.081227</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.393661e+09</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.081642</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   frame.dlt  frame.offset_shift  frame.time_epoch  frame.time_delta  \\\n",
       "0        0.0        1.393661e+09          0.000000          0.000000   \n",
       "0        0.0        1.393661e+09          0.024271          0.024271   \n",
       "0        0.0        1.393661e+09          0.001631          0.001631   \n",
       "0        0.0        1.393661e+09          0.055325          0.055325   \n",
       "0        0.0        1.393661e+09          0.000415          0.000415   \n",
       "\n",
       "   frame.time_delta_displayed  frame.time_relative  frame.len  frame.cap_len  \\\n",
       "0                    0.000000                  261        261              0   \n",
       "0                    0.024271                  185        185              0   \n",
       "0                    0.025902                  185        185              0   \n",
       "0                    0.081227                  159        159              0   \n",
       "0                    0.081642                   54         54              0   \n",
       "\n",
       "   frame.marked  frame.ignored  ...  wlan.ccmp.extiv  wlan.qos.tid  \\\n",
       "0             0              0  ...             <NA>          <NA>   \n",
       "0             0              0  ...             <NA>          <NA>   \n",
       "0             0              0  ...             <NA>          <NA>   \n",
       "0             0              0  ...             <NA>          <NA>   \n",
       "0             0              0  ...             <NA>          <NA>   \n",
       "\n",
       "   wlan.qos.priority  wlan.qos.eosp  wlan.qos.ack  \\\n",
       "0               <NA>           <NA>          <NA>   \n",
       "0               <NA>           <NA>          <NA>   \n",
       "0               <NA>           <NA>          <NA>   \n",
       "0               <NA>           <NA>          <NA>   \n",
       "0               <NA>           <NA>          <NA>   \n",
       "\n",
       "   wlan.qos.buf_state_indicated  wlan.qos.bit4  wlan.qos.txop_dur_req  \\\n",
       "0                          <NA>           <NA>                   <NA>   \n",
       "0                          <NA>           <NA>                   <NA>   \n",
       "0                          <NA>           <NA>                   <NA>   \n",
       "0                          <NA>           <NA>                   <NA>   \n",
       "0                          <NA>           <NA>                   <NA>   \n",
       "\n",
       "   data.len   class  \n",
       "0      <NA>  normal  \n",
       "0      <NA>  normal  \n",
       "0      <NA>  normal  \n",
       "0      <NA>  normal  \n",
       "0      <NA>  normal  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 117)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 200000 entries, 0 to 0\n",
      "Columns: 117 entries, frame.dlt to class\n",
      "dtypes: float64(6), int64(38), object(73)\n",
      "memory usage: 180.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame.dlt</th>\n",
       "      <th>frame.offset_shift</th>\n",
       "      <th>frame.time_epoch</th>\n",
       "      <th>frame.time_delta</th>\n",
       "      <th>frame.time_delta_displayed</th>\n",
       "      <th>frame.time_relative</th>\n",
       "      <th>frame.len</th>\n",
       "      <th>frame.cap_len</th>\n",
       "      <th>frame.marked</th>\n",
       "      <th>frame.ignored</th>\n",
       "      <th>...</th>\n",
       "      <th>radiotap.flags.shortgi</th>\n",
       "      <th>wlan.fc.type_subtype</th>\n",
       "      <th>wlan.fc.version</th>\n",
       "      <th>wlan.fc.type</th>\n",
       "      <th>wlan.fc.ds</th>\n",
       "      <th>wlan.fc.frag</th>\n",
       "      <th>wlan.fc.retry</th>\n",
       "      <th>wlan.fc.pwrmgt</th>\n",
       "      <th>wlan.fc.moredata</th>\n",
       "      <th>wlan.fc.protected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.00000</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.393662e+09</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>573.133998</td>\n",
       "      <td>689.046585</td>\n",
       "      <td>689.046585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.815585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.437805</td>\n",
       "      <td>8.997945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056575</td>\n",
       "      <td>0.011005</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.58098</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.458658e+02</td>\n",
       "      <td>0.010297</td>\n",
       "      <td>0.010297</td>\n",
       "      <td>245.865776</td>\n",
       "      <td>706.985029</td>\n",
       "      <td>706.985029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.773440</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.755840</td>\n",
       "      <td>2.419064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.231029</td>\n",
       "      <td>0.104326</td>\n",
       "      <td>0.030318</td>\n",
       "      <td>0.49340</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.393661e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.393662e+09</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>357.469010</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.393662e+09</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>676.663238</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.393662e+09</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>792.534681</td>\n",
       "      <td>1554.000000</td>\n",
       "      <td>1554.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.393662e+09</td>\n",
       "      <td>0.350263</td>\n",
       "      <td>0.350263</td>\n",
       "      <td>821.828931</td>\n",
       "      <td>1570.000000</td>\n",
       "      <td>1570.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       frame.dlt  frame.offset_shift  frame.time_epoch  frame.time_delta  \\\n",
       "count   200000.0        2.000000e+05     200000.000000     200000.000000   \n",
       "mean         0.0        1.393662e+09          0.004109          0.004109   \n",
       "std          0.0        2.458658e+02          0.010297          0.010297   \n",
       "min          0.0        1.393661e+09          0.000000          0.000000   \n",
       "25%          0.0        1.393662e+09          0.000263          0.000263   \n",
       "50%          0.0        1.393662e+09          0.000510          0.000510   \n",
       "75%          0.0        1.393662e+09          0.001633          0.001633   \n",
       "max          0.0        1.393662e+09          0.350263          0.350263   \n",
       "\n",
       "       frame.time_delta_displayed  frame.time_relative      frame.len  \\\n",
       "count               200000.000000        200000.000000  200000.000000   \n",
       "mean                   573.133998           689.046585     689.046585   \n",
       "std                    245.865776           706.985029     706.985029   \n",
       "min                      0.000000            40.000000      40.000000   \n",
       "25%                    357.469010            54.000000      54.000000   \n",
       "50%                    676.663238           159.000000     159.000000   \n",
       "75%                    792.534681          1554.000000    1554.000000   \n",
       "max                    821.828931          1570.000000    1570.000000   \n",
       "\n",
       "       frame.cap_len  frame.marked  frame.ignored  ...  \\\n",
       "count       200000.0      200000.0       200000.0  ...   \n",
       "mean             0.0           0.0            0.0  ...   \n",
       "std              0.0           0.0            0.0  ...   \n",
       "min              0.0           0.0            0.0  ...   \n",
       "25%              0.0           0.0            0.0  ...   \n",
       "50%              0.0           0.0            0.0  ...   \n",
       "75%              0.0           0.0            0.0  ...   \n",
       "max              0.0           0.0            0.0  ...   \n",
       "\n",
       "       radiotap.flags.shortgi  wlan.fc.type_subtype  wlan.fc.version  \\\n",
       "count           200000.000000              200000.0    200000.000000   \n",
       "mean                36.815585                   0.0         1.437805   \n",
       "std                 20.773440                   0.0         0.755840   \n",
       "min                  1.000000                   0.0         0.000000   \n",
       "25%                 24.000000                   0.0         1.000000   \n",
       "50%                 54.000000                   0.0         2.000000   \n",
       "75%                 54.000000                   0.0         2.000000   \n",
       "max                 54.000000                   0.0         2.000000   \n",
       "\n",
       "        wlan.fc.type  wlan.fc.ds   wlan.fc.frag  wlan.fc.retry  \\\n",
       "count  200000.000000    200000.0  200000.000000  200000.000000   \n",
       "mean        8.997945         0.0       0.056575       0.011005   \n",
       "std         2.419064         0.0       0.231029       0.104326   \n",
       "min         0.000000         0.0       0.000000       0.000000   \n",
       "25%         8.000000         0.0       0.000000       0.000000   \n",
       "50%         8.000000         0.0       0.000000       0.000000   \n",
       "75%         8.000000         0.0       0.000000       0.000000   \n",
       "max        13.000000         0.0       1.000000       1.000000   \n",
       "\n",
       "       wlan.fc.pwrmgt  wlan.fc.moredata  wlan.fc.protected  \n",
       "count   200000.000000      200000.00000           200000.0  \n",
       "mean         0.000920           0.58098                0.0  \n",
       "std          0.030318           0.49340                0.0  \n",
       "min          0.000000           0.00000                0.0  \n",
       "25%          0.000000           0.00000                0.0  \n",
       "50%          0.000000           1.00000                0.0  \n",
       "75%          0.000000           1.00000                0.0  \n",
       "max          1.000000           1.00000                0.0  \n",
       "\n",
       "[8 rows x 44 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['frame.dlt', 'frame.offset_shift', 'frame.time_epoch',\n",
       "       'frame.time_delta', 'frame.time_delta_displayed', 'frame.time_relative',\n",
       "       'frame.len', 'frame.cap_len', 'frame.marked', 'frame.ignored',\n",
       "       ...\n",
       "       'wlan.ccmp.extiv', 'wlan.qos.tid', 'wlan.qos.priority', 'wlan.qos.eosp',\n",
       "       'wlan.qos.ack', 'wlan.qos.buf_state_indicated', 'wlan.qos.bit4',\n",
       "       'wlan.qos.txop_dur_req', 'data.len', 'class'],\n",
       "      dtype='object', length=117)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned dataset\n",
    "df.to_csv(\"./data/cleaned/cleaned_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = pd.read_csv(\"./data/cleaned/cleaned_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XY-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(df_cleaned, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set encoded, shape: (160000, 24999)\n",
      "test_set encoded, shape: (40000, 6372)\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = train_set.select_dtypes(include=['object']).columns.drop(['class', \"wlan.duration\", \"wlan.ra\", \"wlan.da\", \"wlan.ta\", \"wlan.sa\", \"wlan_mgt.tcprep.link_mrg\", \"wlan.wep.key\"])\n",
    "\n",
    "df_train_encoded = pd.get_dummies(train_set, columns=categorical_columns, sparse=True)\n",
    "print(f\"train_set encoded, shape: {df_train_encoded.shape}\")\n",
    "\n",
    "df_test_encoded = pd.get_dummies(test_set, columns=categorical_columns, sparse=True)\n",
    "print(f\"test_set encoded, shape: {df_test_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for columns in categorical_columns:\n",
    "# \tprint(f\"{columns}: {df_cleaned[columns].unique()}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align the train and test sets to ensure they have the same columns\n",
    "df_train_encoded, df_test_encoded = df_train_encoded.align(df_test_encoded, join='outer', axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the encoded dataset\n",
    "# df_train_encoded.to_csv(\"./data/encoded/train_set.csv\", index=False)\n",
    "# df_test_encoded.to_csv(\"./data/encoded/test_set.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Preparing dataset for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Normalise numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all numerical columns\n",
    "# numerical_columns = df_train_encoded.select_dtypes(include=\"number\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1074: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  if np.may_share_memory(array, array_orig):\n"
     ]
    }
   ],
   "source": [
    "numerical_columns = df_train_encoded.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_train_encoded[numerical_columns] = scaler.fit_transform(df_train_encoded[numerical_columns])\n",
    "df_test_encoded[numerical_columns] = scaler.fit_transform(df_test_encoded[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['class', 'data.len', 'frame.cap_len', 'frame.dlt', 'frame.ignored',\n",
       "       'frame.len', 'frame.marked', 'frame.offset_shift', 'frame.time_delta',\n",
       "       'frame.time_delta_displayed',\n",
       "       ...\n",
       "       'wlan_mgt.tagged.all_mhxskl140', 'wlan_mgt.tagged.all_nitsiakos_ti',\n",
       "       'wlan_mgt.tagged.all_paperone wi-fi', 'wlan_mgt.tagged.all_pnet',\n",
       "       'wlan_mgt.tagged.all_steven', 'wlan_mgt.tagged.all_tsoureas',\n",
       "       'wlan_mgt.tcprep.link_mrg', 'wlan_mgt.tim.bmapctl.multicast_0x00',\n",
       "       'wlan_mgt.tim.dtim_count', 'wlan_mgt.tim.dtim_period'],\n",
       "      dtype='object', length=31162)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_encoded.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Map Labels to Multi-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "normal    160000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_encoded[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_mapping = {\n",
    "\t\"normal\": 1,\n",
    "\t\"arp\": 2,\n",
    "\t\"cafe_latte\": 3,\n",
    "\t\"amok\": 4,\n",
    "\t\"deauthentication\": 5,\n",
    "\t\"authentication_request\": 6,\n",
    "\t\"evil_twin\": 7,\n",
    "\t\"beacon\": 8,\n",
    "\t\"probe_response\": 9,\n",
    "\t\"fragmentation\": 10\n",
    "}\n",
    "\n",
    "df_train_encoded[\"class\"] = df_train_encoded[\"class\"].map(attack_mapping)\n",
    "df_test_encoded[\"class\"] = df_test_encoded[\"class\"].map(attack_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "1    160000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_encoded[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train_encoded\n",
    "df_test = df_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=\"class\")\n",
    "y = df[\"class\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. PyTorch Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NetworkIDSModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NetworkIDSModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "# Define the input size (number of features), hidden layers, and output size (number of classes)\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 64  # You can experiment with this\n",
    "output_size = len(attack_mapping)  # Depends on binary or multi-class\n",
    "\n",
    "model = NetworkIDSModel(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harman\\AppData\\Local\\Temp\\ipykernel_23316\\149408932.py:20: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  X_train_tensor = torch.tensor(X_train_subset.values, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm  # Import tqdm for progress bars\n",
    "\n",
    "# Ensure all values in X_train are numeric\n",
    "X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
    "y_train = y_train.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values that may have been introduced\n",
    "# X_train.dropna(inplace=True)\n",
    "# y_train.dropna(inplace=True)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "# Ensure labels are mapped to integers\n",
    "y_train = y_train.map(attack_mapping)\n",
    "\n",
    "X_train_subset = X_train.sample(frac=0.1)  # Use 10% of the data\n",
    "y_train_subset = y_train.loc[X_train_subset.index]\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_subset.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_subset.values, dtype=torch.int64)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/400 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target -9223372036854775808 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m     21\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m---> 22\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Backward pass and optimize\u001b[39;00m\n\u001b[0;32m     25\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Harman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Harman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Harman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1293\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Harman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:3479\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3478\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3486\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: Target -9223372036854775808 is out of bounds."
     ]
    }
   ],
   "source": [
    "# Ensure all labels are valid integers\n",
    "invalid_labels = y_train_tensor[y_train_tensor < 0]\n",
    "if len(invalid_labels) > 0:\n",
    "    print(f\"Invalid labels found: {invalid_labels}\")\n",
    "    y_train_tensor = y_train_tensor[y_train_tensor >= 0]\n",
    "\n",
    "# Training loop with tqdm\n",
    "num_epochs = 10  # You can experiment with this\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Use tqdm to display the progress for each batch\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as tepoch:\n",
    "        for data, labels in tepoch:\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Track loss and accuracy\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Calculate batch accuracy\n",
    "            batch_accuracy = correct / total\n",
    "            \n",
    "            # Update the progress bar for each batch\n",
    "            tepoch.set_postfix(loss=total_loss / (tepoch.n + 1), accuracy=batch_accuracy)\n",
    "    \n",
    "    # Epoch-level logging (average metrics for the epoch)\n",
    "    epoch_loss = total_loss / len(train_loader)\n",
    "    epoch_accuracy = correct / total\n",
    "    print(f'[Epoch {epoch+1}/{num_epochs}]: loss: {epoch_loss:.4f} ; accuracy: {epoch_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert test data to tensor\n",
    "y_test = y_test.map(attack_mapping).astype(int)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Make predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\toutputs = model(X_test_tensor)\n",
    "\t_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct = (predicted == y_test_tensor).sum().item()\n",
    "accuracy = correct / len(y_test_tensor)\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './models/ids_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./models/ids_model.pth', weights_only=True))\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
